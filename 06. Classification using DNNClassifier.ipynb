{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/uzumaki/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race   gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White     Male          2174   \n",
       "1     Exec-managerial         Husband   White     Male             0   \n",
       "2   Handlers-cleaners   Not-in-family   White     Male             0   \n",
       "3   Handlers-cleaners         Husband   Black     Male             0   \n",
       "4      Prof-specialty            Wife   Black   Female             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country income_bracket  \n",
       "0             0              40   United-States          <=50K  \n",
       "1             0              13   United-States          <=50K  \n",
       "2             0              40   United-States          <=50K  \n",
       "3             0              40   United-States          <=50K  \n",
       "4             0              40            Cuba          <=50K  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"datasets/census_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"income_bracket\"] = df[\"income_bracket\"].apply(lambda x: 0 if x == \" <=50K\" else 1)\n",
    "df[\"gender\"] = df[\"gender\"].apply(lambda x: 0 if \" Male\" else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>education_num</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>native_country</th>\n",
       "      <th>income_bracket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   education  education_num       marital_status  \\\n",
       "0   39          State-gov   Bachelors             13        Never-married   \n",
       "1   50   Self-emp-not-inc   Bachelors             13   Married-civ-spouse   \n",
       "2   38            Private     HS-grad              9             Divorced   \n",
       "3   53            Private        11th              7   Married-civ-spouse   \n",
       "4   28            Private   Bachelors             13   Married-civ-spouse   \n",
       "\n",
       "           occupation    relationship    race  gender  capital_gain  \\\n",
       "0        Adm-clerical   Not-in-family   White       0          2174   \n",
       "1     Exec-managerial         Husband   White       0             0   \n",
       "2   Handlers-cleaners   Not-in-family   White       0             0   \n",
       "3   Handlers-cleaners         Husband   Black       0             0   \n",
       "4      Prof-specialty            Wife   Black       0             0   \n",
       "\n",
       "   capital_loss  hours_per_week  native_country  income_bracket  \n",
       "0             0              40   United-States               0  \n",
       "1             0              13   United-States               0  \n",
       "2             0              40   United-States               0  \n",
       "3             0              40   United-States               0  \n",
       "4             0              40            Cuba               0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_cols = ['age', 'workclass', 'education', 'education_num', 'marital_status',\n",
    "       'occupation', 'relationship', 'race', 'gender', 'capital_gain',\n",
    "       'capital_loss', 'hours_per_week', 'native_country']\n",
    "X = df[dep_cols]\n",
    "y = df[\"income_bracket\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = tf.feature_column.numeric_column(\"age\")\n",
    "\n",
    "workclass = tf.feature_column \\\n",
    "              .categorical_column_with_vocabulary_list(\"workclass\", \n",
    "                    vocabulary_list=[' State-gov', ' Self-emp-not-inc', ' Private', ' Federal-gov',\n",
    "                                     ' Local-gov', ' ?', ' Self-emp-inc', ' Without-pay',\n",
    "                                     ' Never-worked'])\n",
    "    \n",
    "workclass_embedding = tf.feature_column.embedding_column(workclass, dimension=9)\n",
    "    \n",
    "education = tf.feature_column \\\n",
    "              .categorical_column_with_vocabulary_list(\"education\",\n",
    "                    vocabulary_list=[' Bachelors', ' HS-grad', ' 11th', ' Masters', ' 9th',\n",
    "                                     ' Some-college', ' Assoc-acdm', ' Assoc-voc', ' 7th-8th',\n",
    "                                     ' Doctorate', ' Prof-school', ' 5th-6th', ' 10th', ' 1st-4th',\n",
    "                                     ' Preschool', ' 12th'])\n",
    "education_embedding = tf.feature_column.embedding_column(education, dimension=16)\n",
    "    \n",
    "education_num = tf.feature_column.numeric_column(\"education_num\")\n",
    "\n",
    "marital_status = tf.feature_column \\\n",
    "                   .categorical_column_with_vocabulary_list(\"marital_status\",\n",
    "                        vocabulary_list=[' Never-married', ' Married-civ-spouse', ' Divorced',\n",
    "                                         ' Married-spouse-absent', ' Separated', ' Married-AF-spouse',\n",
    "                                         ' Widowed'])\n",
    "\n",
    "marital_status_embedding = tf.feature_column.embedding_column(marital_status, dimension=7)\n",
    "\n",
    "occupation = tf.feature_column \\\n",
    "               .categorical_column_with_vocabulary_list(\"occupation\",\n",
    "                        vocabulary_list=[' Adm-clerical', ' Exec-managerial', ' Handlers-cleaners',\n",
    "                                        ' Prof-specialty', ' Other-service', ' Sales', ' Craft-repair',\n",
    "                                        ' Transport-moving', ' Farming-fishing', ' Machine-op-inspct',\n",
    "                                        ' Tech-support', ' ?', ' Protective-serv', ' Armed-Forces',\n",
    "                                        ' Priv-house-serv'])\n",
    "\n",
    "occupation_embedding = tf.feature_column.embedding_column(occupation, dimension=15)\n",
    "\n",
    "relationship = tf.feature_column \\\n",
    "                 .categorical_column_with_vocabulary_list(\"relationship\",\n",
    "                        vocabulary_list=[' Adm-clerical', ' Exec-managerial', ' Handlers-cleaners',\n",
    "                                        ' Prof-specialty', ' Other-service', ' Sales', ' Craft-repair',\n",
    "                                        ' Transport-moving', ' Farming-fishing', ' Machine-op-inspct',\n",
    "                                        ' Tech-support', ' ?', ' Protective-serv', ' Armed-Forces',\n",
    "                                        ' Priv-house-serv'])\n",
    "\n",
    "relationship_embedding = tf.feature_column.embedding_column(relationship, dimension=15)\n",
    "    \n",
    "race = tf.feature_column \\\n",
    "         .categorical_column_with_vocabulary_list(\"race\",\n",
    "                        vocabulary_list=[' White', ' Black', ' Asian-Pac-Islander', ' Amer-Indian-Eskimo',\n",
    "                                         ' Other'])\n",
    "\n",
    "race_embedding = tf.feature_column.embedding_column(race, dimension=5)\n",
    "\n",
    "gender = tf.feature_column.numeric_column(\"gender\")\n",
    "\n",
    "capital_gain = tf.feature_column.numeric_column(\"capital_gain\")\n",
    "\n",
    "capital_loss = tf.feature_column.numeric_column(\"capital_loss\")\n",
    "\n",
    "hours_per_week = tf.feature_column.numeric_column(\"hours_per_week\")\n",
    "\n",
    "native_country = tf.feature_column \\\n",
    "                   .categorical_column_with_vocabulary_list(\"native_country\",\n",
    "                        vocabulary_list=[' United-States', ' Cuba', ' Jamaica', ' India', ' ?', ' Mexico',\n",
    "                                        ' South', ' Puerto-Rico', ' Honduras', ' England', ' Canada',\n",
    "                                        ' Germany', ' Iran', ' Philippines', ' Italy', ' Poland',\n",
    "                                        ' Columbia', ' Cambodia', ' Thailand', ' Ecuador', ' Laos',\n",
    "                                        ' Taiwan', ' Haiti', ' Portugal', ' Dominican-Republic',\n",
    "                                        ' El-Salvador', ' France', ' Guatemala', ' China', ' Japan',\n",
    "                                        ' Yugoslavia', ' Peru', ' Outlying-US(Guam-USVI-etc)', ' Scotland',\n",
    "                                        ' Trinadad&Tobago', ' Greece', ' Nicaragua', ' Vietnam', ' Hong',\n",
    "                                        ' Ireland', ' Hungary', ' Holand-Netherlands'])\n",
    "\n",
    "native_country_embedding = tf.feature_column.embedding_column(native_country, dimension=42)\n",
    "\n",
    "feat_cols = [age, workclass_embedding, education_embedding, education_num, marital_status_embedding,\n",
    "             occupation_embedding, relationship_embedding, race_embedding, gender, capital_gain,\n",
    "             capital_loss, hours_per_week, native_country_embedding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_function = tf.estimator.inputs.pandas_input_fn(X_train, y_train, shuffle=True, num_epochs=1000,\n",
    "                                                     batch_size=10)\n",
    "test_function = tf.estimator.inputs.pandas_input_fn(X_test, y_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpa4mdugmv\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpa4mdugmv', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6d20d89cf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "dnn_estimator = tf.estimator.DNNClassifier(hidden_units=[30, 30, 30, 30], feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpa4mdugmv/model.ckpt.\n",
      "INFO:tensorflow:loss = 7.3872576, step = 1\n",
      "INFO:tensorflow:global_step/sec: 61.6554\n",
      "INFO:tensorflow:loss = 40.076103, step = 101 (1.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 111.968\n",
      "INFO:tensorflow:loss = 11.375727, step = 201 (0.892 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.3793\n",
      "INFO:tensorflow:loss = 2.808196, step = 301 (1.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.6367\n",
      "INFO:tensorflow:loss = 3.1784146, step = 401 (1.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.1863\n",
      "INFO:tensorflow:loss = 2.0526948, step = 501 (1.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.8485\n",
      "INFO:tensorflow:loss = 6.0254064, step = 601 (1.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.7898\n",
      "INFO:tensorflow:loss = 2.7700462, step = 701 (1.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.7819\n",
      "INFO:tensorflow:loss = 2.7362747, step = 801 (1.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.245\n",
      "INFO:tensorflow:loss = 1.3773125, step = 901 (1.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.8084\n",
      "INFO:tensorflow:loss = 6.028972, step = 1001 (1.264 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.8285\n",
      "INFO:tensorflow:loss = 2.5915234, step = 1101 (1.620 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.7133\n",
      "INFO:tensorflow:loss = 3.760437, step = 1201 (1.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.0842\n",
      "INFO:tensorflow:loss = 3.2354314, step = 1301 (1.750 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.3854\n",
      "INFO:tensorflow:loss = 7.420515, step = 1401 (1.707 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.1991\n",
      "INFO:tensorflow:loss = 2.5371046, step = 1501 (1.687 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.3499\n",
      "INFO:tensorflow:loss = 1.4301318, step = 1601 (1.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 104.812\n",
      "INFO:tensorflow:loss = 6.038348, step = 1701 (0.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.9788\n",
      "INFO:tensorflow:loss = 0.9903154, step = 1801 (1.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.589\n",
      "INFO:tensorflow:loss = 3.5265086, step = 1901 (1.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 100.003\n",
      "INFO:tensorflow:loss = 8.414541, step = 2001 (1.002 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.2928\n",
      "INFO:tensorflow:loss = 2.227357, step = 2101 (1.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.434\n",
      "INFO:tensorflow:loss = 3.522572, step = 2201 (0.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.1875\n",
      "INFO:tensorflow:loss = 2.6261146, step = 2301 (1.013 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.1053\n",
      "INFO:tensorflow:loss = 3.2685337, step = 2401 (1.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.3007\n",
      "INFO:tensorflow:loss = 1.3836997, step = 2501 (1.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.2445\n",
      "INFO:tensorflow:loss = 5.375405, step = 2601 (1.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.9795\n",
      "INFO:tensorflow:loss = 2.6114142, step = 2701 (1.733 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.7304\n",
      "INFO:tensorflow:loss = 3.1075163, step = 2801 (1.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.3932\n",
      "INFO:tensorflow:loss = 5.3248553, step = 2901 (1.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.0371\n",
      "INFO:tensorflow:loss = 1.5833045, step = 3001 (1.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.5716\n",
      "INFO:tensorflow:loss = 6.239983, step = 3101 (1.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.422\n",
      "INFO:tensorflow:loss = 2.7466397, step = 3201 (1.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.5466\n",
      "INFO:tensorflow:loss = 4.1402574, step = 3301 (1.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.0105\n",
      "INFO:tensorflow:loss = 4.146605, step = 3401 (1.749 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.7684\n",
      "INFO:tensorflow:loss = 3.999049, step = 3501 (1.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.9193\n",
      "INFO:tensorflow:loss = 1.6640154, step = 3601 (1.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.738\n",
      "INFO:tensorflow:loss = 4.873273, step = 3701 (1.673 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.7692\n",
      "INFO:tensorflow:loss = 3.0208778, step = 3801 (1.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.1422\n",
      "INFO:tensorflow:loss = 4.281498, step = 3901 (1.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.7705\n",
      "INFO:tensorflow:loss = 0.8552084, step = 4001 (1.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.305\n",
      "INFO:tensorflow:loss = 4.8767395, step = 4101 (1.638 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.6228\n",
      "INFO:tensorflow:loss = 4.245371, step = 4201 (1.625 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.7399\n",
      "INFO:tensorflow:loss = 3.805955, step = 4301 (1.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.089\n",
      "INFO:tensorflow:loss = 3.6052613, step = 4401 (1.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.0775\n",
      "INFO:tensorflow:loss = 4.4645605, step = 4501 (1.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.6238\n",
      "INFO:tensorflow:loss = 12.6875925, step = 4601 (1.652 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.4401\n",
      "INFO:tensorflow:loss = 2.9324818, step = 4701 (1.549 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.4797\n",
      "INFO:tensorflow:loss = 2.2682352, step = 4801 (1.579 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.2864\n",
      "INFO:tensorflow:loss = 2.7954948, step = 4901 (1.581 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.19\n",
      "INFO:tensorflow:loss = 2.0626779, step = 5001 (1.533 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.8767\n",
      "INFO:tensorflow:loss = 2.0656977, step = 5101 (1.542 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.7015\n",
      "INFO:tensorflow:loss = 2.1274931, step = 5201 (1.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.4482\n",
      "INFO:tensorflow:loss = 2.4990377, step = 5301 (1.684 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.5321\n",
      "INFO:tensorflow:loss = 5.165595, step = 5401 (1.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.9747\n",
      "INFO:tensorflow:loss = 2.183177, step = 5501 (1.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.3644\n",
      "INFO:tensorflow:loss = 4.057462, step = 5601 (1.556 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.8017\n",
      "INFO:tensorflow:loss = 4.766465, step = 5701 (1.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.4696\n",
      "INFO:tensorflow:loss = 1.0847702, step = 5801 (1.558 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.5874\n",
      "INFO:tensorflow:loss = 6.856576, step = 5901 (1.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.3135\n",
      "INFO:tensorflow:loss = 1.1573782, step = 6001 (1.650 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.356\n",
      "INFO:tensorflow:loss = 8.086438, step = 6101 (1.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.9723\n",
      "INFO:tensorflow:loss = 1.3443226, step = 6201 (1.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.4656\n",
      "INFO:tensorflow:loss = 4.2824283, step = 6301 (1.601 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.7708\n",
      "INFO:tensorflow:loss = 4.279273, step = 6401 (1.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.208\n",
      "INFO:tensorflow:loss = 3.548825, step = 6501 (0.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.246\n",
      "INFO:tensorflow:loss = 3.3903944, step = 6601 (0.905 sec)\n",
      "INFO:tensorflow:global_step/sec: 108.06\n",
      "INFO:tensorflow:loss = 2.393199, step = 6701 (0.923 sec)\n",
      "INFO:tensorflow:global_step/sec: 98.9696\n",
      "INFO:tensorflow:loss = 2.1231508, step = 6801 (1.012 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.5017\n",
      "INFO:tensorflow:loss = 4.962467, step = 6901 (1.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 87.0698\n",
      "INFO:tensorflow:loss = 4.755313, step = 7001 (1.166 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.1617\n",
      "INFO:tensorflow:loss = 2.8699536, step = 7101 (1.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.8626\n",
      "INFO:tensorflow:loss = 1.2472588, step = 7201 (1.065 sec)\n",
      "INFO:tensorflow:global_step/sec: 91.1666\n",
      "INFO:tensorflow:loss = 3.6851306, step = 7301 (1.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 101.87\n",
      "INFO:tensorflow:loss = 2.1378622, step = 7401 (0.982 sec)\n",
      "INFO:tensorflow:global_step/sec: 105.3\n",
      "INFO:tensorflow:loss = 3.537009, step = 7501 (0.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.2628\n",
      "INFO:tensorflow:loss = 5.1913495, step = 7601 (1.661 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.6572\n",
      "INFO:tensorflow:loss = 9.37588, step = 7701 (1.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.2916\n",
      "INFO:tensorflow:loss = 2.541063, step = 7801 (1.659 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.2006\n",
      "INFO:tensorflow:loss = 5.2867603, step = 7901 (1.674 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.8675\n",
      "INFO:tensorflow:loss = 1.1192365, step = 8001 (1.704 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 58.1761\n",
      "INFO:tensorflow:loss = 4.0737305, step = 8101 (1.712 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.4095\n",
      "INFO:tensorflow:loss = 1.0111527, step = 8201 (1.710 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.8456\n",
      "INFO:tensorflow:loss = 1.3702941, step = 8301 (1.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.1702\n",
      "INFO:tensorflow:loss = 3.192575, step = 8401 (1.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.0965\n",
      "INFO:tensorflow:loss = 1.3611094, step = 8501 (1.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.0734\n",
      "INFO:tensorflow:loss = 2.5777082, step = 8601 (1.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.1413\n",
      "INFO:tensorflow:loss = 2.0858414, step = 8701 (1.777 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.6146\n",
      "INFO:tensorflow:loss = 3.1641831, step = 8801 (1.630 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.8385\n",
      "INFO:tensorflow:loss = 2.792842, step = 8901 (1.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.1643\n",
      "INFO:tensorflow:loss = 1.4624512, step = 9001 (1.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 60.8625\n",
      "INFO:tensorflow:loss = 1.4590924, step = 9101 (1.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.7698\n",
      "INFO:tensorflow:loss = 1.1732023, step = 9201 (1.616 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.2779\n",
      "INFO:tensorflow:loss = 3.8676186, step = 9301 (1.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.2092\n",
      "INFO:tensorflow:loss = 2.5647526, step = 9401 (1.605 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.4629\n",
      "INFO:tensorflow:loss = 2.2068539, step = 9501 (1.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.2467\n",
      "INFO:tensorflow:loss = 4.7059774, step = 9601 (1.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.5451\n",
      "INFO:tensorflow:loss = 3.0565305, step = 9701 (1.582 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.0396\n",
      "INFO:tensorflow:loss = 2.5969687, step = 9801 (1.642 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.3082\n",
      "INFO:tensorflow:loss = 4.631242, step = 9901 (1.624 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/tmpa4mdugmv/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3.1183615.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7f6d21aca470>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_estimator.train(input_fn=train_function, steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-03-10-17:29:55\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpa4mdugmv/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-03-10-17:30:00\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.84072065, accuracy_baseline = 0.7592384, auc = 0.8966845, auc_precision_recall = 0.73977774, average_loss = 0.33734277, global_step = 10000, label/mean = 0.2407616, loss = 42.79872, prediction/mean = 0.25810185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.84072065,\n",
       " 'accuracy_baseline': 0.7592384,\n",
       " 'auc': 0.8966845,\n",
       " 'auc_precision_recall': 0.73977774,\n",
       " 'average_loss': 0.33734277,\n",
       " 'global_step': 10000,\n",
       " 'label/mean': 0.2407616,\n",
       " 'loss': 42.79872,\n",
       " 'prediction/mean': 0.25810185}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_estimator.evaluate(input_fn=test_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
